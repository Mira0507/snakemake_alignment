### 1. Paired end 

- config/config_paired.yaml

```yaml

###################### Sample info ######################

SAMPLE:
  SRR8245176: Untreated1
  SRR8245177: Untreated2
  SRR8245178: Untreated3
  SRR8245179: Treated1
  SRR8245180: Treated2
  SRR8245181: Treated3
  




END: 
  - 1
  - 2


SRA:
  - SRR8245176
  - SRR8245177
  - SRR8245178
  - SRR8245179
  - SRR8245180
  - SRR8245181
  

FASTQ_PREFIX:
  - Untreated1
  - Untreated2
  - Untreated3
  - Treated1
  - Treated2
  - Treated3
  


###################### Reference info ######################
  
REFERENCE_LINK:
  GENOME: 
    - 'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/GRCh38.primary_assembly.genome.fa.gz'
    - 'GRCh38.primary_assembly.genome.fa.gz'
    - 'GRCh38.primary_assembly.genome.fa'
  ANNOTATION: 
    - 'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/gencode.v37.primary_assembly.annotation.gtf.gz'
    - 'gencode.v37.primary_assembly.annotation.gtf.gz'
    - 'gencode.v37.primary_assembly.annotation.gtf'


###################### Extra-setting info ######################

INDEX_STAR: "/home/mira/Documents/programming/Bioinformatics/snakemake_star_hisat/reference/star_index" # Assigns path to star indexing directory (ABSOLUTE PATH NEEDED due to a potential STAR error!)

INDEX_HISAT: "reference/hisat2_index/hisat2_index" # Assigns hisat2 index files (e.g.reference/hisat2_index/hisat2_index.1.ht2, reference/hisat2_index/hisat2_index.2.ht2, ...)


FASTQ_EXT: '.fastq.gz'

CONDA: "config/conda_r.yaml"

RCONFIG: 'config/config_single.R'
  

  
```

- Snakefile

```

#################################### Defined by users #################################
configfile: "config/config_paired.yaml"    # Sets path to the config file
#######################################################################################

shell.prefix('set -euo pipefail; ')
shell.executable('/bin/bash')



rule all: 
    input: 
        "DE_analysis/DE.html"

rule get_fastq:   # Creates fastq.gz files in fastq directory
    """
    This rule downloads SRA and converts to FASTQ files
    """
    output:
        expand("fastq/{sample}_{end}.fastq.gz", sample=config['FASTQ_PREFIX'], end=config['END'])  # Gzipped FASTQ files from SRA 
    params:
        dic=config['SAMPLE'],   # Sample dictionary
        reads=config['END'],    # Reads (e.g. [1] or [1, 2]) 
        sra=config['SRA']       # SRA number 
    run:
        shell("fastq-dump --split-files {params.sra} --gzip")    # with or without -X 100000
        for key, value in params.dic.items(): 
              for read in params.reads: 
                  shell("mv {key}_{read}.fastq.gz fastq/{value}_{read}.fastq.gz") 


rule get_reference:    
    """
    This rule downloads reference files
    """
    params:
        gen_link=config['REFERENCE_LINK']['GENOME'][0],   # Gencode reference genome file link 
        gen_name=config['REFERENCE_LINK']['GENOME'][1],   # Output reference genome location & name 
        anno_link=config['REFERENCE_LINK']['ANNOTATION'][0],  # Gencode GTF (annotation) file link
        anno_name=config['REFERENCE_LINK']['ANNOTATION'][1]   # Output GTF file location & name
    output:
        gen=expand("reference/{gen}", gen=config['REFERENCE_LINK']['GENOME'][2]),  # Decompressed reference genome file 
        anno=expand("reference/{anno}", anno=config['REFERENCE_LINK']['ANNOTATION'][2])  # Decompressed GTF file
    shell:
        "set +o pipefail; "
        "wget -c {params.gen_link} -O reference/{params.gen_name} && "
        "wget -c {params.anno_link} -O reference/{params.anno_name} && "
        "gzip -d reference/*.gz"

rule index_hisat2:
    """
    This rule constructs HISAT2 index files
    """
    input: 
        expand("reference/{gen}", gen=config['REFERENCE_LINK']['GENOME'][2])    # Decompressed reference genome file
    output:
        expand("reference/hisat2_index/hisat2_index.{number}.ht2", number=[x+1 for x in range(8)])   # HISAT2 indexing files
    threads: 8
    shell:
        "set +o pipefail; "
        "hisat2-build -f -o 4 "
        "-p {threads} "
        "--seed 67 "
        "{input} "
        "hisat2_index && "
        "mv *.ht2 reference/hisat2_index"


rule index_star:
    """
    This rule constructs STAR index files
    """
    input:
        fa=expand("reference/{gen}", gen=config['REFERENCE_LINK']['GENOME'][2]),  # Decompressed reference genome file
        gtf=expand("reference/{anno}", anno=config['REFERENCE_LINK']['ANNOTATION'][2])  # Decompressed GTF file
    output:
        "reference/star_index/Genome",   # STAR indexing files
        "reference/star_index/SA",       # STAR indexing files
        "reference/star_index/SAindex"   # STAR indexing files
    threads: 10
    shell:
        "set +o pipefail; "
        "STAR --runThreadN {threads} "
        "--runMode genomeGenerate "
        "--genomeDir reference/star_index "
        "--genomeFastaFiles {input.fa} "
        "--sjdbGTFfile {input.gtf}"




rule align_hisat2:    # Creates bam files in hisat2_output directory"
    """
    This rule aligns the reads using HISAT2    
    """
    input:
        fastq=expand("fastq/{sample}_{end}.fastq.gz", sample=config['FASTQ_PREFIX'], end=config['END']),  # Gzipped FASTQ files
        index=expand("reference/hisat2_index/hisat2_index.{number}.ht2", number=[x+1 for x in range(8)])  # HISAT2 indexing files
    output:
        expand("hisat2_output/{sample}.bam", sample=config['FASTQ_PREFIX']),   # Bam files
        temp(expand("hisat2_output/{sample}.sam", sample=config['FASTQ_PREFIX']))
    params:
        files=config["FASTQ_PREFIX"],  # e.g. Ctrl, Treatment
        ext=config['FASTQ_EXT'],       # extension of the FASTQ files (e.g. .fastq.gz)
        indexing=config['INDEX_HISAT'] # HISAT2 indexing location and file name prefix
    threads: 8
    run:
        for i in range(len(params.files)):
            p=params.files[i]
            r1= "fastq/" + params.files[i] + "_1" + params.ext 
            r2=""
            read="-U " + r1
            if len(input.fastq) == 2 * len(params.files): 
                r2= "fastq/" + params.files[i] + "_2" + params.ext  
                read="-1 " + r1 + " -2 " + r2
            shell("hisat2 -q -p {threads} "
                  "--seed 23 "
                  "--summary-file hisat2_output/summary_{p}.txt "
                  "-x {params.indexing} "
                  "{read} "
                  "-S hisat2_output/{p}.sam && "
                  "samtools view -bS "
                  "-@ {threads} "
                  "hisat2_output/{p}.sam > hisat2_output/{p}.bam")



rule align_star:   # Creates bam files in star_output directory"
    """
    This rule aligns the reads using STAR two-pass mode
    """
    input:
        gtf=expand("reference/{gen}", gen=config['REFERENCE_LINK']['ANNOTATION'][2]),  # Decompressed GTF file
        fastq=expand("fastq/{sample}_{end}.fastq.gz", sample=config['FASTQ_PREFIX'], end=config['END']),                  # Gzipped FASTQ files
        index1="reference/star_index/Genome",
        index2="reference/star_index/SA",
        index3="reference/star_index/SAindex"
    output:
        expand("star_output/{sample}Aligned.sortedByCoord.out.bam", sample=config['FASTQ_PREFIX'])  # Bam files
    params:
        indexing=config["INDEX_STAR"],  # STAR indexing file directory
        files=config["FASTQ_PREFIX"],   # e.g. Ctrl, Treatment
        ext=config['FASTQ_EXT']         # extension of the FASTQ files (e.g. fastq.gz)
    threads: 10
    run:
        for i in range(len(params.files)):
            p=params.files[i]
            r1= "fastq/" + params.files[i] + "_1" + params.ext + " " 
            r2=""
            if len(input.fastq) == 2 * len(params.files): 
                r2= "fastq/" + params.files[i] + "_2" + params.ext + " " 
            shell("STAR --runThreadN {threads} "  
                    "--runMode alignReads "  
                    "--readFilesCommand zcat "
                    "--genomeDir {params.indexing} " 
                    "--sjdbGTFfile {input.gtf} "  
                    "--sjdbOverhang 100 "  
                    "--readFilesIn {r1}{r2}"  
                    "--outFileNamePrefix star_output/{p} "
                    "--outFilterType BySJout "  
                    "--outFilterMultimapNmax 20 "
                    "--alignSJoverhangMin 8 "
                    "--alignSJDBoverhangMin 1 "
                    "--outFilterMismatchNmax 999 "
                    "--outFilterMismatchNoverReadLmax 0.04 "
                    "--alignIntronMin 20 "
                    "--alignIntronMax 1000000 "
                    "--outSAMunmapped None "
                    "--outSAMtype BAM "
                    "SortedByCoordinate "
                    "--quantMode GeneCounts "
                    "--twopassMode Basic "
                    "--chimOutType Junctions")     



rule featurecounts:
    """
    This rule assesses read counts using featureCounts
    """
    input:
        star=expand("star_output/{sample}Aligned.sortedByCoord.out.bam", sample=config['FASTQ_PREFIX']),  # Bam files from STAR
        hisat2=expand("hisat2_output/{sample}.bam", sample=config['FASTQ_PREFIX'])    # Bam files from HISAT2
    params:
        ends=config['END'], # Read ends (e.g. [1] or [1, 2])
        gtf=expand("reference/{anno}", anno=config['REFERENCE_LINK']['ANNOTATION'][2])  # Decompressed GTF file
    output:
        star="star_output/featurecounts.tsv",  # Read count tsv file (STAR version)
        hisat2="hisat2_output/featurecounts.tsv"  # Read count tsv file (HISAT2 version)
    threads: 16
    run:
        count_star=output.star
        count_hisat2=output.hisat2
        bam_star=input.star
        bam_hisat2=input.hisat2
        end=""
        if len(params.ends) == 2:
            end='-p'
        # Additional featureCounts flags
        # -F: format of the annotation file. 'GTF' by default.
        # -g: attribute type. 'gene_id' by default. 
        # -L: set for long-read inputs 
        # -s: strand-specificity. 0 (unstranded & default), 1 (stranded), 2 (reversely stranded)
        shell("set +o pipefail; "
              "featureCounts {end} "    
              "-s0 "
              "-T {threads} "
              "-a {params.gtf} "
              "-o {count_star} "
              "{bam_star} &> {count_star}.log && "
              "featureCounts {end} "    
              "-s0 "
              "-T {threads} "
              "-a {params.gtf} "
              "-o {count_hisat2} "
              "{bam_hisat2} &> {count_hisat2}.log")



rule deseq2:
    """
    This rule performs differential expression (DE) analysis using DESeq2 in R
    """
    input:
        star_reads="star_output/featurecounts.tsv",  # Assessed read counts from STAR aligner 
        hisat2_reads="hisat2_output/featurecounts.tsv",  # Assessed read counts from HISAT2 aligner
        rmd="DE_analysis/DE.Rmd",                    # R scripts for downstream DE analysis
        rconfig=config["RCONFIG"]                    # config file for Rmd 
    output:
        "DE_analysis/DE.html",           # Output html file from Rmd 
        "DE_analysis/lfc_STAR.csv",      # DESeq2 result from STAR-mediated alignment 
        "DE_analysis/lfc_HISAT2.csv",    # DESeq2 result from HISAT2-mediated alignment
        "DE_analysis/baseMean_difference.csv",        # Gene discordance table in baseMean
        "DE_analysis/log2FoldChange_difference.csv",  # Gene discordance table in log2FoldChange
        "DE_analysis/padj_difference.csv",            # Gene discordance table in padj
        temp("DE_analysis/trf_input.fa") 
    conda:
        config['CONDA']                           # conda env config file
    shell:
        "Rscript -e \"rmarkdown::render('{input.rmd}')\""   # Requires "snakemake -j 8 --use-conda" command when running snakemake

```


- DE.Rmd


```

---
title: "STAR vs HISAT2 (Focused on Mean/Fold/FDR)"
author: "Mira Sohn" 
output:
    html_document:
        self_contained: false
---

```{r global_options, include=FALSE}


knitr::opts_chunk$set(
    warning=FALSE,
    message=FALSE
    )


```



## Loading packages

#### - **AnnotationHub**: https://bioconductor.org/packages/devel/bioc/vignettes/AnnotationHub/inst/doc/AnnotationHub.html

#### - **DESeq2**: http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html

```{r loading_packages}

library(data.table)
library(tidyverse)
library(rmarkdown)
library(ggplot2)
library(pheatmap)
library(AnnotationHub)
library(DESeq2)
library(UpSetR)
library(ensembldb)
library(gridExtra)
library(httr) 
library(jsonlite) 

```


## Loading R config file 


```{r}

source("../config/config_paired.R")

```


## Setting AnnotationHub



```{r annotationhub}

DB <- my.anno.db                     # Set your DB of interest
AnnotationSpecies <- my.species      # Set your species of interest
ah <- AnnotationHub(hub=getAnnotationHubOption("URL"))  # Bring annotation DB



# Filter annotation of interest
ahQuery <- query(ah, 
                 pattern=c(DB, AnnotationSpecies), 
                 ignore.case=T)      


# Select the most recent data
DBName <- mcols(ahQuery) %>%
    rownames() %>%
    tail(1)

anno.db <- ah[[DBName]] 

# Explore your EnsDb object with following accessors:
# columns(AnnpDb)
# keytypes(AnnoDb)
# keys(AnnoDb, keytype=..)
# select(AnnoDb, keys=.., columns=.., keytype=...)
AnnoKey <- keys(anno.db, keytype="TXID")
# Note: Annotation has to be done with not genome but transcripts 
AnnoDb <- select(anno.db, 
                 AnnoKey,
                 keytype="TXID",
                 columns=c("TXID", "GENEID", "GENENAME"))


# Check if your AnnoDb has been extracted and saved correctely
class(AnnoDb)
head(AnnoDb)    # The column 1 has to assign transcript (e.g. ENSEMBLTRANS)
```



## Loading count matrices 


```{r read_countmatrix}

# Import read count matrices and clean the data frame

# Assign column names that will be deleted 
trim.col <- c("Chr", "Start", "End", "Strand", "Length")

# Aligner names
Aligners <- c("HISAT2", "STAR")

# Create an empty list for storing imported and cleaned count matrices
countList <- list()

for (x in Aligners) {

    # Import the count tsv file
    df <- read.table(featurecounts.path[[x]], 
                     sep="\t", 
                     header=T) 

    # Deleted redundant columns
    df <- df[, !(colnames(df) %in% trim.col)]

    # Save the imported & cleaned count data frame
    countList[[x]] <- df

}


# Explore the output
head(countList[[1]])
head(countList[[2]])

dim(countList[[1]])
dim(countList[[2]])

```




## Metadata setting

```{r generating_metadata}

# Import your sample table 
SampleTable <- read.csv(sample.csv)


# Define sample names 
SampleNames <- SampleTable$sample


# Define group level
GroupLevel <- unique(SampleTable$group)

# Define contrast for DE analysis
Contrast <- c("Group", GroupLevel)

# Define group names
GroupNames <- SampleTable$group


# Create metadata
metadata <- data.frame(Sample=factor(SampleNames, levels=SampleNames),
                       Group=factor(GroupNames, levels=GroupLevel))

# Assign row names with sample names
rownames(metadata) <- SampleNames


# Explore the metadata
print(metadata)


```



## Data cleaning: sample and gene annotation


```{r count_dataframe_cleaning}



# Set a function cleaning the count data frame
clean.fn <- function(df) {

    # Convert to a data frame
    df <- as.data.frame(df)

    # Assign column names
    names(df) <- c("GENEID", SampleNames)


    return(df)
}


# Set a function to drop GENEID version
clean.annotation.fn <- function(df) {

    # Re-annotate without version specification
    df <- separate(df, "GENEID", c("GENEID", "Version"))

    # Remove version column
    df <- df[, colnames(df) != "Version"]

    return(df)
}

# Move GENEID to a column
for (x in Aligners) {

    countList[[x]] <- clean.fn(countList[[x]])

}


# Remove version of GENEID and duplicated rows in STAR & HISAT2 count tables
for (x in Aligners) {

    countList[[x]] <- clean.annotation.fn(countList[[x]]) %>% 

        distinct()

}



# Explore the cleaned count data frames 
head(countList[[1]])
head(countList[[2]])
dim(countList[[1]])
dim(countList[[2]])
sum(duplicated(countList[[1]]))
sum(duplicated(countList[[2]]))



```



## Plotting sequencing depth 

#### Number of total counts per sample

```{r library_size}

# Set a function generating a data frame with sequencing depth
seq.depth.fn <- function(df, aligner) {

    seqdf <- as.data.frame(colSums(df[, SampleNames])) %>% 
        rownames_to_column (var="Sample") %>% 
        mutate(Aligner=aligner)

    names(seqdf) <- c("Sample", "Count", "Aligner")

    return(seqdf)
}

# Set a function for a bar plot comparing values
comparing.barplot.fn <- function(df, yval, title, ytitle) {

    ggplot(df, 
       aes(x=Sample, y=yval, group=Aligner, fill=Aligner)) +
    geom_bar(stat="identity", position="dodge") +
    theme_bw() +
    theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1)) +
    ggtitle(title) + 
    ylab(ytitle)

}




# Initialize the seq depth data frame with the first aligner
seq.depth.df <- seq.depth.fn(countList[[1]], Aligners[1])

# Extend the seq depth data frame with the rest of aligners
for (x in Aligners) {

    if (x %in% Aligners[2:length(Aligners)]) {

        seq.depth.df <- rbind(seq.depth.df, 
                              seq.depth.fn(countList[[x]], x))
    }
}

# Explore how the data frame 
print(seq.depth.df)
summary(seq.depth.df)

# Convert character vectors to factors
seq.depth.df$Sample <- factor(seq.depth.df$Sample, 
                              levels=SampleNames)
seq.depth.df$Aligner <- factor(seq.depth.df$Aligner, 
                               levels=Aligners)

# Create a plot presenting sequencing depth
comparing.barplot.fn(seq.depth.df, 
                     seq.depth.df$Count, 
                     "Sequencing Depth by Sample and Aligner", 
                     "Count")

```

## Generating DESeq2 objects

#### - **vst()** was run to perform variance stabilizing transformation instead of rlog() which takes longer time with similar characteristics. 

#### - The **vsd** object created by vst() is used for not DE analysis but QC.

#### - References: [**DESeq2 doc "Transcript abundance files"**](https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#tximport), [**DESeq2 doc "Variance stabilizing transformation"**](https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#variance-stabilizing-transformation)

```{r generating_deseq2_objects}

# Initialize new lists for storing dds objects
ddsList <- list()

# Initialize new lists for storing vsd objects
vsdList <- list()


for (x in Aligners) {

    # Create a count matrix from the count data frame 
    m <- countList[[x]][, colnames(countList[[x]]) != "GENEID"] %>% 
        as.matrix()

    # Assigne row names
    rownames(m) <- countList[[x]]$GENEID

    # Generate a DESeq2 object
    ddsList[[x]] <- DESeqDataSetFromMatrix(m, 
                                           colData=metadata, 
                                           design=~Group) 

    # Conduct vst
    vsdList[[x]] <- varianceStabilizingTransformation(ddsList[[x]], 
                                                      blind=TRUE) 
}

# Explore generated objects
summary(ddsList)
summary(vsdList)


```


## Estimating size factors

#### - black dashed line: size factor = 1

#### - Reference: [**DESeq2 doc "Sample-/gene-dependent normalization factors"**](https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#log-fold-change-shrinkage-for-visualization-and-ranking)


```{r size_factors}

# Calculate and add size factors to the DEseq object
for (x in Aligners) {

    ddsList[[x]] <- estimateSizeFactors(ddsList[[x]])

}

# Set a function summarizing size factors by aligner to a data frame
sfactor.fn <- function(df, aligner) {

    sizefactor <- as.data.frame(round(sizeFactors(df), 3)) %>%
        rownames_to_column(var="Sample") %>%
        mutate(Aligner=aligner)

    names(sizefactor) <- c("Sample", "Size_Factor", "Aligner")

    return(sizefactor)

}

# Initialize a data frame with the first aligner 
size.factor.df <- sfactor.fn(ddsList[[1]], Aligners[1])


for (x in Aligners) {

    if (x != Aligners[1]) {

        size.factor.df <- rbind(size.factor.df, 
                                sfactor.fn(ddsList[[x]], x))
    }
}


# Explore the data frame
print(size.factor.df)

# Convert character vectors to factors
size.factor.df$Sample <- factor(size.factor.df$Sample, 
                              levels=SampleNames)
size.factor.df$Aligner <- factor(size.factor.df$Aligner, 
                               levels=Aligners)

# Plot calculated size factors
comparing.barplot.fn(size.factor.df, 
                     size.factor.df$Size_Factor,  
                     "Size Factors by Aligner and Sample", 
                     "Size Factor") + geom_hline(yintercept=1, linetype="dashed", color="black", size=1)

```


## Estimating dispersion and Wald test

#### - **Dispersion** is calculated as a **measure of variation** instead of variance since variance gets larger when gene expression gets higher. 

#### - **Wald test** is the default setting of DESeq2 which tests null hypothesis between **two groups**. You should use **Likelihood ratio test (LRT)** when comparing **more than two groups**. 

#### - References: [**Harvard Chan Bioinformatics Core workshop I**](https://github.com/hbctraining/DGE_workshop_salmon_online/blob/master/lessons/05b_wald_test_results.md), [**Harvard Chan Bioinformatics Core workshop II**](https://github.com/hbctraining/DGE_workshop_salmon_online/blob/master/lessons/05a_hypothesis_testing.md), [**Harvard Chan Bioinformatics Core workshop III**](https://github.com/hbctraining/DGE_workshop_salmon_online/blob/master/lessons/04b_DGE_DESeq2_analysis.md), [**DESeq2 "Wald test indivisual steps**](https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#wald-test-individual-steps), [**DESeq2 doc "Likelihood ratio test"**](https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#likelihood-ratio-test)

```{r dispersion_waldtest}

for (x in Aligners) {

    # Dispersion
    ddsList[[x]] <- estimateDispersions(ddsList[[x]])
    
    # Wald test
    ddsList[[x]] <- nbinomWaldTest(ddsList[[x]])

}


# Explore generated data in the dds object 
ddsList[[1]]

```

## Sample QC: Principal Component Analysis (PCA)

#### Identifies source of variation and sample outliers

#### - Reference: [**DESeq2 doc "Principal component plot of the samples"**](https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#principal-component-plot-of-the-samples), [**DESeq2 doc "Heatmap of the sample-to-sample distances"**](https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#heatmap-of-the-sample-to-sample-distances)

```{r QC_PCA}

# Print PCA plots 
for (x in Aligners) {

    # Vsd object
    my.vsd <- vsdList[[x]]

    # Aligner name
    my.aligner <- x

    # Print the PCA result
    print(plotPCA(my.vsd, 
                  intgroup=Contrast[1],
                  returnData=F) + 
          theme_bw() + 
          ggtitle(paste("PCA:", my.aligner)))

}



```

## Sample QC: Sample Correlation Heatmap

#### Identifies distance between samples & correlation in a group

```{r QC_correlation_heatmap}

# Heatmap annotation
HeatmapAnno <- metadata[, c("Sample", "Group")]

for (x in Aligners) {

    # Extract a normalized count matrix 
    vm <- assay(vsdList[[x]])

    # Generate a correlation matrix
    cm <- cor(vm)

    # Print a heatmap
    print(pheatmap(cm, 
                   annotation=HeatmapAnno,
                   main=paste("Sample Correlation Heatmap:", 
                              x)))

}


```

## Running DE analysis


```{r DE_analysis}



# Run DESeq 
for (x in Aligners) {

    ddsList[[x]] <- DESeq(ddsList[[x]])
    # Check result names 
    ResNames <- resultsNames(ddsList[[x]])
    print(ResNames)

}


```

## Creating dispersion plots


#### - Dispersion is important since estimation by DESeq2 algorithm is based on the assumption that genes with similar expression levels have similar dispersion. If an RNA-seq dataset doesn't satisfy this assumption, use other DE algorithms than DESeq2. 

#### - References: [**DESeq2 doc "Dispersion plot and fitting alternatives**](https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#dispersion-plot-and-fitting-alternatives), [**Harvard Chan Bioinformatics Core workshop **](https://github.com/hbctraining/DGE_workshop_salmon_online/blob/master/lessons/04b_DGE_DESeq2_analysis.md)

```{r dispersion_plot}


for (x in Aligners) {

    # Assign input
    dds <- ddsList[[x]]

    # Print the dispersion plot
    print(plotDispEsts(dds, 
                       main=paste("Dispersion over Counts:", 
                                  x)))

}




# Do they fit well with the DESeq2 estimation model?

```

## Setting how to extract fold-change results

#### Change variables below

#### - The **alpha** denotes threshold of **false discovery rate (FDR)** assigned by users.

#### - In this analysis, the alpha is set to **0.1** 

```{r setting_resultcondition}



# Set the coefficients to compare 
Coef <- ResNames[-1]
print(Coef) 



# Set a function to clean a result table 
lfctable.fn <- function(df) {
    df <- df %>% 
        rownames_to_column(var="GENEID") %>%
        mutate(FDR=ifelse(padj < 0.1 & !is.na(padj), 
                                   paste("<", alpha),
                                   paste(">", alpha)))
    return(df)
}

# Set a function extracting results
extract.lfc.fn <- function(dds) {

    res <- results(dds, contrast=Contrast, alpha=alpha)

    return(lfctable.fn(as.data.frame(res)))


}

```


## Extracting log2FoldChanges

#### You can change alpha depending on your interest of FDR level

#### Shrinkage is NOT applied in this analysis





```{r DEresult_extraction}

# Initialize a list storing lfc data frames
lfcList <- list()

# Extract DE results
# The Contrast variable was defined in the previous chunk
# Extraction with no shrinkage
# alpha: FDR threshold
for (x in Aligners) {

    lfcList[[x]] <- extract.lfc.fn(ddsList[[x]]) %>% mutate(Alignment=x) 

    write.csv(lfcList[[x]], paste0("lfc_", x, ".csv"))

    print(head(lfcList[[x]]))

}

# Initialize a data frame storing total lfc results across the aligners
lfc.dataframe <- lfcList[[1]] 

for (x in Aligners[2:length(Aligners)]) {

    lfc.dataframe <- rbind(lfc.dataframe, 
                           lfcList[[x]])

}


lfc.dataframe$Alignment <- factor(lfc.dataframe$Alignment, 
                                  levels=Aligners)


```



## Exploring distribution of false discovery rate (FDR)

#### Black dashed line: FDR

```{r FDR_distribution}

# Plot distribution of FDR 
ggplot(lfc.dataframe, 
       aes(x=padj, y=..count.., color=Alignment)) + 
    geom_density(size=1) + 
    theme_bw() + 
    ggtitle("Distribution of False Discovery Rate (FDR) by Aligner") + 
    ylab("Count") +
    xlim(0.00001, 1) + 
    geom_vline(xintercept=alpha, 
               color="black", 
               size=1, linetype="dashed") + 
    scale_x_continuous(breaks=seq(0, 1, by=0.1))



```

## Presenting distribution of log2FoldChange

### Black: total genes (padj =/= NA)
### Colored: genes above or below FDR=0.1


```{r L2FC_distribution}

valid.lfc.df <- subset(lfc.dataframe, FDR == paste("<",  alpha))

ggplot(valid.lfc.df,
       aes(x=log2FoldChange,
           y=..count.., 
           color=Alignment)) +
geom_density(size=1) + 
theme_bw() + 
geom_vline(xintercept=c(-1, 1), 
           linetype="dashed", color="black", size=1) + 
ggtitle(paste0("Distribution of log2FoldChange Values by Aligner (FDR < ", alpha, ")")) +
ylab("Count") + 
xlim(-10, 10)    # Change xlim by datatype

```


## Exploring mean-difference with an MA plot

#### - Reference: [**DESeq2 doc "MA-plot"**](https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#ma-plot)

#### - **x-axis**: expression level (baseMean)

#### - **y-axis**: fold change (log2FoldChange)

#### - **Red dashed lines**: log2FoldChange = -1 and 1 

```{r MAplot}




# Create MA plots by Aligner
ggplot(lfc.dataframe, aes(x=baseMean, y=log2FoldChange, color=FDR)) + 
        geom_point() + 
        facet_grid(~Alignment) +
        scale_x_log10() + 
        theme_bw() + 
        scale_color_manual(values=c("blue", "grey")) + 
        ggtitle(paste("MA plot")) +
        theme(strip.text.x=element_text(size=10)) +
        geom_hline(yintercept=c(mLog[1], mLog[2]), 
                   linetype="dashed", color="red", size=1) 


```

## Exploring expression profiling with normalized count data

#### - Normalized count matrices are extracted from dds objects and filtered with thresholds set at FDR and log2FoldChange

#### - The heatmaps display **z-scores** of the normalized counts

#### - In this analysis, **mLog = 1** by default (see config.R file)

#### - References: [**Harvard Chan Bioinformatics Core workshop**](https://github.com/hbctraining/DGE_workshop_salmon_online/blob/master/lessons/06_DGE_visualizing_results.md), [**DESeq2 doc "Heatmap of the count matrix"**](https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#heatmap-of-the-count-matrix)

```{r expression_heatmap}

# Initialize a list 
heatmap.df.List <- list()

# Filter genes with FDR < alpha and absolute log2FoldChange > 1
for (x in Aligners) {

    # Set a logical vector filtering FDR below alpha
    is.fdr.valid <- lfcList[[x]]$FDR == paste("<", alpha)

    # Set a logical vector filtering absolute lfc above 1 
    is.lfc.large <- abs(lfcList[[x]]$log2FoldChange) > mLog[2]

    # Extract total normalized counts
    norm.counts <- counts(ddsList[[x]], normalized=T)

    # Save filtered genes only from the normalized count data
    heatmap.df.List[[x]] <- norm.counts[is.fdr.valid & is.lfc.large,]

}

# Explore the cleaned data frames 
head(heatmap.df.List[[1]])
head(heatmap.df.List[[2]])

dim(heatmap.df.List[[1]])
dim(heatmap.df.List[[2]])


for (x in Aligners) {

    # Assign the input data frame
    df <- heatmap.df.List[[x]]

    # Print the heatmap
    print(pheatmap(df,
                   annotation=HeatmapAnno, 
                   scale="row",
                   show_rownames=F,
                   main=paste("Expression Profiling by", 
                              x, 
                              paste0("(FDR < ", 
                                     alpha,
                                     ", absolute log2FoldChange > ",
                                     mLog[1]))))

}


```



## NA statistics: zero count genes & outlier genes

#### When NAs appear in  

#### - **log2FoldChange**: zero counts in all samples

#### - **padj**: too little information 

#### - **pval & padj**: at least one replicate was an outlier 

```{r NA_genes}

# Count number of NA genes  
type=c("Zero Counts", "Outliers", "Total NA Genes") 

# Create a data frame storing number of NA genes by type
NA.genes <- lfc.dataframe %>% 
    group_by(Alignment) %>% 
    summarize(zero=sum(is.na(log2FoldChange)), 
              outlier=sum(is.na(pvalue) & is.na(padj))) %>% 
    mutate(total=zero + outlier) %>%
    gather(Type, Number, -Alignment) %>% 
    mutate(Type=factor(case_when(Type == "zero" ~ type[1],
                                 Type == "outlier" ~ type[2],
                                 Type == "total" ~ type[3]),
                       levels=type))

# Plot number of NA genes 
ggplot(NA.genes, 
       aes(x=Type, y=Number, group=Alignment, fill=Alignment, label=Number)) + 
    geom_bar(stat="identity", position="dodge") + 
    theme_bw() +
    geom_text(position=position_dodge(width=1), vjust=1.5) + 
    ggtitle("Number of NA Genes") + 
    ylab("Number of Genes")


```

## baseMean/LFC/FDR comparison between aligners 




```{r diff_prep}



# Create a data frame storing the number of transcripts by gene id
AnnoDb.ntrans <- AnnoDb %>% 
    group_by(GENEID) %>% 
    summarize(Alternative.Transcripts=n_distinct(TXID))

# Create an empty list storing significant gene lfc tables 
sigList <- list() 


# Filter significant genes' lfc and save in the list 
for (x in Aligners) {


    sigList[[x]] <- subset(lfcList[[x]], FDR == paste("<", alpha))

}

# Create a vector storing column names
c_names <- colnames(sigList[[1]])[-1] 
c_names <- c("GENEID", 
             paste0(c_names, "_", Aligners[1]), 
             paste0(c_names, "_", Aligners[2]))


# Join tables by GENEID
lfcTable <- sigList[[1]] %>% 
    inner_join(sigList[[2]], by="GENEID") 

# Rename the columns
names(lfcTable) <- c_names





# Calculate differences
lfcTable <- lfcTable %>%

    mutate(mean_ST_HI=baseMean_STAR - baseMean_HISAT2, 
           lfc_ST_HI=log2FoldChange_STAR - log2FoldChange_HISAT2,
           FDR_ST_HI=padj_STAR - padj_HISAT2) %>% 
            left_join(AnnoDb.ntrans, by="GENEID")




# Explore the output table
head(lfcTable)
dim(lfcTable)

```

## Relationship between baseMean/log2FoldChange/padj with the number of alternative transcripts 

#### - Variables of interest: baseMean, log2FoldChange, and padj 

#### - R-squared: tests whether the two variables are correlated




```{r comparison, fig_width=12}


my.param <- c("baseMean", "log2FoldChange", "padj")


# Slice and clean the data frame for input
lfcTable.comp <- lfcTable %>% 
    dplyr::select(GENEID, Alternative.Transcripts, starts_with(my.param)) %>% 
    gather(Category, Value, -GENEID, -Alternative.Transcripts) %>% 
    separate(Category, c("Metric", "Aligner"), sep="_") %>% pivot_wider(names_from=Aligner, values_from=Value) %>% 
    group_by(Metric) %>%
    nest() %>% 

    # Calculate correlation coefficients between aligners by metric
    mutate(star.hisat.corr=map_dbl(data, ~ cor(.x$STAR, .x$HISAT2)),
           data=map2(data, 
                     star.hisat.corr,
                     ~ mutate(.x, Rsquared=c(.y, rep("", nrow(.x)-1))))) %>%

    # Unnest
    unnest(data) 

# Explore the cleaned data frame
head(lfcTable.comp)


# Create scatter plots comparing HISAT2 and STAR alignment results
ggplot(lfcTable.comp,
       aes(x=HISAT2, 
           y=STAR, 
           color=log(Alternative.Transcripts), 
           label=Rsquared)) + 
geom_point(alpha=0.5) + 
theme_bw() + 
facet_wrap(~ Metric, scales="free") + 
theme(strip.text.x=element_text(size=10)) +
geom_text(size=5, 
          mapping=aes(x=Inf, y=Inf), 
          vjust=2, hjust=1.2, color="black") +
geom_abline(slope=1, size=0.5, linetype="dashed", color="black") + 
ggtitle("HISAT2 vs STAR comparison (with R-Squared)") + scale_color_gradient(low="blue", high="red") 

```


## Distribution of baseMean/log2FoldChange/padj between HISAT2 and STAR 

#### - P-Values: determines whether distribution of the values is different with statistical significance using Two-tailed t-test



```{r distribution, fig.height=12, fig.width=12}


# Clean the data frame 
lfcTable.rel <- lfcTable %>%
    dplyr::select(starts_with(c(my.param, "GENEID"))) %>% 
    gather(Key, Value, -GENEID) %>% 
    separate(Key, c("Metric", "Aligner"), sep="_") %>% 
    group_by(Metric) %>%
    nest() %>%
    mutate(ttest=map_dbl(data, ~ t.test(.x$Value ~ .x$Aligner, data=.x)$p.value),
           data=map2(data, 
                     ttest, 
                     ~ mutate(.x, Pval=c(.y, rep("", nrow(.x)-1))))) %>% 
    unnest(data) %>%
    mutate(Log.Value=log(Value)) %>% 
    gather(Transformation, Value, Value, Log.Value) %>% 
    mutate(Transformation=ifelse(Transformation == "Value",
                                 "Original", 
                                 "Log-Transformed"),
           Transformation=factor(Transformation, 
                                 levels=c("Original", "Log-Transformed")))

# Create boxplots presenting the distribution    
ggplot(lfcTable.rel,
       aes(x=Aligner,
           y=Value, 
           label=Pval)) +
geom_jitter(alpha=0.5, aes(color=Aligner)) + 
geom_boxplot(data=lfcTable.rel, 
             alpha=0.5, outlier.alpha=0, aes(x=Aligner, y=Value)) + 
theme_bw() + 
facet_wrap(Transformation ~ Metric, scales="free") + 
xlab("Aligner") + 
ylab("Value") +
geom_text(size=5, mapping=aes(x=Inf, y=Inf), vjust=2, hjust=1.2) + 
theme(strip.text.x=element_text(size=10)) + 
ggtitle("Distribution Comparison (with P-Value from Two-Tailed T-Test)") 






```


## Exploring relationship between absolute difference/percent difference vs the number of alternative transcripts 

#### - Absolute Difference: HISAT2 - STAR

#### - Percent Difference: 100 x (abs(HISAT2 - STAR) / HISAT2 + STAR)


```{r percent_difference, fig.width=12}

# Add columns storing percent difference
lfcTable <- lfcTable %>%

    # mDiff: difference in meanBase
    # lDiff: difference in log2FoldChange
    # fDiff: difference in padj (FDR)
    mutate(mDiff_percent=100 * mean_ST_HI / (baseMean_STAR + baseMean_HISAT2),
           lDiff_percent=100 * lfc_ST_HI / 
               (abs(log2FoldChange_STAR) + abs(log2FoldChange_HISAT2)),
           fDiff_percent=100 * FDR_ST_HI / (padj_STAR + padj_HISAT2))

# Explore the output
head(lfcTable)
dim(lfcTable)

# Create an empty data frame
lfcTable.percent <- data.frame()


for (x in my.param) {

    
    init.vec <- c("GENEID", "Alternative.Transcripts")

    # Set columns of interest
    if (x == my.param[1]) { 

        col.of.interest <- c(init.vec, "mean_ST_HI", "mDiff_percent")

    } else if (x == my.param[2]) {

        col.of.interest <- c(init.vec, "lfc_ST_HI", "lDiff_percent")

    } else {

        col.of.interest <- c(init.vec, "FDR_ST_HI", "fDiff_percent") 

    }



    # Trim the table 
    df <- lfcTable[, colnames(lfcTable) %in% col.of.interest] %>%
        mutate(Metric=x) %>%
        dplyr::rename(Absolute.Difference=ends_with("HI"), 
                      Percent.Difference=ends_with("percent"))    

    # Save in the empty data frame 
    if (x == my.param[1]) {

        lfcTable.percent <- df

    } else {

        lfcTable.percent <- rbind(lfcTable.percent, df)

    }


}

# Explore the output
head(lfcTable.percent)
dim(lfcTable.percent)


# Nest the data frame by Metric
lfcTable.percent <- lfcTable.percent %>%
    group_by(Metric) %>%
    nest()

# Explore the output
lfcTable.percent
head(lfcTable.percent$data[[1]])


# Calculate correlation (Rsquared) 
# DvsP: Percent Difference vs Difference
lfcTable.percent <- lfcTable.percent %>%
    mutate(Mod=map(data, ~ lm(Percent.Difference ~ Absolute.Difference, data=.x)),
           rsq=map_dbl(Mod, ~ summary(.x)$r.squared),
           data=map2(data, 
                     rsq, 
                     ~ mutate(.x, 
                                Rsquared=c(.y, rep("", nrow(.x)-1))))) %>%

    unnest(data)



# Explore the output data frame
head(lfcTable.percent)

# Print the plots
ggplot(lfcTable.percent, 
       aes(x=abs(Absolute.Difference),
           y=abs(Percent.Difference),
           color=log(Alternative.Transcripts),
           label=Rsquared)) + 
    geom_point(alpha=0.5) + 
    theme_bw() + 
    scale_color_gradient(low="blue", high="red") + 
    facet_wrap(~Metric, scales = "free") + 
    theme(strip.text.x=element_text(size=10)) + 
    geom_text(size=5, 
              aes(x=Inf, y=Inf), 
              vjust=2, hjust=1.1, color="black") +
    ggtitle("Discordance between HISAT2 and STAR") + 
    xlab("Absolute Difference\n(HISAT2 - STAR)") + 
    ylab("Percent Difference\n(100 x (HISAT2 - STAR) / (HISAT2 + STAR))")




```


## Comparison of Ranking between HISAT2 and STAR in baseMean/log2FoldChange/FDR



```{r ranking_comparison_prep}

# Set a function rearranging a data frame
rank.fn <- function(df, var, desc=F) { 
    
    if (desc) { 

        df <- dplyr::arrange(df, desc(var)) 

    } else {

        df <- dplyr::arrange(df, var) 

    }


    return(df)

}


# Set a function creating a rank plot
rank.plot.fn <- function(df, metric, colog=F) { 


    if (colog) { 

        p <- ggplot(df, aes(x=Rank.x, 
                            y=Rank.y, 
                            color=log(MeanValue), 
                            label=Rsquared))

    } else {

        p <- ggplot(df, aes(x=Rank.x, 
                            y=Rank.y, 
                            color=MeanValue,
                            label=Rsquared))

    }
    
    p <- p + 
        geom_point(alpha=0.5) + 
        theme_bw() + 
        scale_color_gradient(low="blue", high="red") + 
        xlab("Rank in HISAT2") + 
        ylab("Rank in STAR") + 
        ggtitle(paste("Rank Comparison in", metric, "\n(with R-Squared)")) + geom_text(size=5, 
                mapping=aes(x=Inf, y=Inf), vjust=2, hjust=1, color="black") +
        geom_abline(slope=1, size=0.5, linetype="dashed", color="black")  

    return(p)

}


```


```{r ranking_comparison, fig.width=12}



# Clean the data frame 
lfcTable.rank <- lfcTable %>% 

    # Splice by columns of interest
    dplyr::select(GENEID, 
                  starts_with(c("baseMean_", "log2FoldChange_", "padj_"))) %>% 

    # Reform the table
    gather(Metric, Value, -GENEID) %>%

    # Nest by Metric
    group_by(Metric) %>%
    nest() %>% 

    # Add columns storing ascending or descending order by variable of interest
    mutate(Ascending=map(data, ~ rank.fn(.x, .x$Value)), 
           Descending=map(data, ~ rank.fn(.x, .x$Value, T)),
           Final=map2(Ascending, 
                      Descending, 
                      ~ ifelse(Metric %in% c("padj_HISAT2", "padj_STAR"),
                               Ascending, 
                               Descending)), 
           Final=map(Final, ~ .x[[1]]),

           # Add a column storing rank
   Final=map(Final, ~ mutate(.x, Rank=1:nrow(.x)))) %>%

    # Unnest 
    unnest(Final) %>% 

    # Reform the table 
    separate(Metric, c("Metric", "Aligner")) %>% 
    dplyr::select(-data, -Ascending, -Descending) %>%

    # Renest by metric
    group_by(Metric) %>%
    nest() %>%

    # Reclean the data frame 
    mutate(Split=map(data, ~ split(.x, .x$Aligner)),
           Joined=map(Split, ~ inner_join(.x[[1]], 
                                          .x[[2]], 
                                          by=c("GENEID")))) %>%
    dplyr::select(-data, -Split) %>%

    # Unnest
    unnest(Joined) %>%

    # Calculate and save MeanRank and MeanValue
    mutate(MeanRank=(Rank.x + Rank.y)/2, 
           MeanValue=abs((Value.x + Value.y)/2)) %>% 

    # Nest by Metric
    nest(-Metric) %>%

    # Add a column storing R^2
    mutate(rsq=map_dbl(data, ~ cor(.x$Rank.x, .x$Rank.y)),
           data=map2(data, 
                     rsq, 
                     ~ mutate(.x, 
                              Rsquared=c(.y, 
                                         rep("", nrow(.x)-1))))) %>%


    # Add columns storing scatter plots
    mutate(RankPlot=map(data, ~ rank.plot.fn(.x, Metric)), 
           RankPlot.log=map(data, ~ rank.plot.fn(.x, Metric, T)))


# Explore the data frame 
head(lfcTable.rank)
head(lfcTable.rank$data[[1]])



# Explore the plots
for (i in 1:3) {

    print(grid.arrange(lfcTable.rank$RankPlot[[i]],
                       lfcTable.rank$RankPlot.log[[i]], nrow=1))


}




# Complete the optimal presentation for the plots
grid.arrange(lfcTable.rank$RankPlot.log[[1]], 
             lfcTable.rank$RankPlot.log[[2]], 
             lfcTable.rank$RankPlot[[3]], nrow=1) 


```





## Saving difference tables 


```{r saving_diff_csv}

lfcTable.discordance <- data.frame()


for (x in my.param) {

    # Subset by metric
    df <- subset(lfcTable.percent, Metric == x)[, 1:5]


    # Rearrange the data frame using the function rank.fn() set previously
    df <- rank.fn(df, abs(df$Percent.Difference), desc=T) 

    # Save the output in the lfcTable.discordance data frame by rbinding
    lfcTable.discordance <- rbind(lfcTable.discordance, 
                                  df)

    # Print the output data frame
    print(head(df)) 


    # Save as a csv file
    write.csv(df, 
              paste0(x, "_difference.csv"))

    


}


# Explore the output data frame
head(lfcTable.discordance)
dim(lfcTable.discordance)
glimpse(lfcTable.discordance)

```


## Comparing the number of repetitive elements


#### - Tandem Repeats Finder (TRF): [Web](https://tandem.bu.edu/trf/trf.html), [Linux Version](https://tandem.bu.edu/trf/trf.unix.help.html), [Reference paper](https://pubmed.ncbi.nlm.nih.gov/9862982)


#### - Genomic sequences were retrieved by using the Ensembl API [GET sequence/id/:id](https://rest.ensembl.org/documentation/info/sequence_id)


```{r count_repetitive_elements}

# Create a vector storing unique GENEID
geneid <- unique(lfcTable.discordance$GENEID)


# Assign the server for API 
server <- "https://rest.ensembl.org"


for (i in 1:length(geneid)) {


    # Retrieve data using ensembl gene ids 
    ext <- paste0("/sequence/id/",
                  geneid[i],
                  "?")

    r <- GET(paste(server, ext, sep = ""), content_type("text/plain"))
     
    stop_for_status(r)

    line1 <- paste0(">", geneid[i]) 
    line2 <- content(r)

    write(line1, file="trf_input.fa", append=T)
    write(line2, file="trf_input.fa", append=T)


}



# Run tandem repeats finder (trf): only takes fasta format as an input file  
system("trf trf_input.fa 2 7 7 80 10 50 500 -d -h")  # Returns a .dat file 

# Convert the TRF result .dat data to a data frame
trflines <- readLines("trf_input.fa.2.7.7.80.10.50.500.dat")

trfTable <- data.frame()
for (i in 7:length(trflines)) {

    if (trflines[i] != "" & !grepl("Parameters", trflines[i], fixed=T)) {



        trflines[i] <- str_replace(trflines[i], "Sequence: ", "")

        df <- data.frame(Line=trflines[i])

        trfTable <- rbind(trfTable, df)

    }

}


# Clean the TRF data frame
trfTable <- trfTable %>%
    mutate(code=ifelse(grepl(geneid.species, Line, fixed=T), 
                       "ID", 
                       "DNA")) 






# Extract the number of repetitive elements per GENEID
trfnumTable <- data.frame()
code.vector <- trfTable$code

GENE <- c()
COUNT <- c()

index.id <- 0
index.dna <- 0
for (i in 1:nrow(trfTable)) {


    if (code.vector[i] == "ID") {

        index.id <- index.id + 1
        index.dna <- 0

    } else {

        index.id <- 0
        index.dna <- index.dna + 1
    }



    GENE[i] <- index.id # Indicates GENEID coded "ID"
    COUNT[i] <- index.dna  # Indicates repetitive elements coded "DNA" 


}

repetitive.geneid <- which(COUNT == 1) - 1  # right before the first repetitive elements
repetitive.first <- which(COUNT == 1)  # the first repetitive elements 
repetitive.last <- which(GENE == 1) - 1  # the last repetitive elements per GENEID 

# Explore the indices
repetitive.geneid
repetitive.first
repetitive.last


# In case that the first gene had one repetitive element: 
if (repetitive.last[1] < repetitive.first[1]) {

    repetitive.last <- repetitive.last[-1]

    if (repetitive.last[length(repetitive.last)] < 
        repetitive.first[length(repetitive.first)]) {

        repetitive.last <- c(repetitive.last, 
                             repetitive.first[length(repetitive.first)])

    }



}

# Explore the indices
repetitive.geneid
repetitive.first
repetitive.last

trfnumTable <- data.frame(GENEID=trfTable$Line[repetitive.geneid],
                          Repeats_First=repetitive.first, 
                          Repeats_Last=repetitive.last) %>% 
mutate(Repetitive.Elements=Repeats_Last - Repeats_First + 1)


# Join the TRF result with the discordance data frame
lfcTable.discordance <- lfcTable.discordance %>%
    inner_join(trfnumTable, by="GENEID") 

# Remove duplicated rows
lfcTable.discordance <- lfcTable.discordance[!duplicated(lfcTable.discordance),]

# Explore the output data frame
glimpse(lfcTable.discordance)



```


## Comparing the number of variant alleles

#### - The number of variants were retrieved by using the [Ensembl REST API (GET overlap/id/:id)](https://rest.ensembl.org/documentation/info/overlap_id)

#### - Reference: [The Ensembl Variant Effect Predictor (McLaren et al., 2016)](https://pubmed.ncbi.nlm.nih.gov/27268795)



```{r count_variants}


# Create an empty vector storing the number of variant alleles per gene id 
variants.vec <- c()

for (i in 1:length(geneid)) {


    # Retrieve data using ensembl gene ids 
    ext <- paste0("/overlap/id/",
                  geneid[i],
                  "?feature=variation")

    r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
     
    stop_for_status(r)

    # Extract the variant ids 
    df <- data.frame(t(sapply(content(r),c))) %>% 
        gather("Variable", "Value") %>% 
        dplyr::filter(str_detect(Value, "rs"))

    # Count the number of variant ids and save
   variants.vec <- c(variants.vec, length(unique(df$Value)))

}


# Save gene ids and the number of variant alleles as a data frame 
var.df <- data.frame(GENEID=geneid, 
                     Variant.Alleles=variants.vec)

# Explore the output data frame
head(var.df)
dim(var.df)


# Combine the number of variant alleles to the percent discordance table 
lfcTable.discordance <- lfcTable.discordance %>%
    inner_join(var.df,
               by="GENEID")

# Explore the combined data frame
head(lfcTable.discordance)
glimpse(lfcTable.discordance)




```


## Investigating relationship between alignment discordance and the number of alternative transcripts/variant alleles/repetitive elements


```{r clean_plot_data, fig.height=12, fig.width=12}

# Clean the data frame
lfcTable.summary <- lfcTable.discordance %>%
    group_by(Metric, GENEID) %>%
    summarize(Percent.Difference=abs(Percent.Difference),
              Absolute.Difference=abs(Absolute.Difference),
              Alternative.Transcripts=Alternative.Transcripts,
              Variant.Alleles=Variant.Alleles,
              Repetitive.Elements=Repetitive.Elements) 

# Remove duplicated rows 
lfcTable.summary <- lfcTable.summary[!duplicated(lfcTable.summary),]

# Explore the cleaned output data frame
head(lfcTable.summary)
dim(lfcTable.summary)
glimpse(lfcTable.summary)


# Clean and nest the data frame
lfcTable.nested <- lfcTable.summary %>%
    gather(Difference, 
           Difference.Value, 
           Percent.Difference, 
           Absolute.Difference) %>% 
    gather(Variable, 
           Variable.Value, 
           Alternative.Transcripts,
           Variant.Alleles,
           Repetitive.Elements) %>%
    group_by(Metric, Variable, Difference) %>%
    nest() %>%

    # Create linear regression models & calculate p-values
    mutate(Mod=map(data, ~ lm(.x$Difference.Value ~ 
                                  .x$Variable.Value, data=.x)),
           R.Squared=map_dbl(Mod, ~ summary(.x)$r.squared),
           data=map2(data, 
                     R.Squared,
                     ~ mutate(.x, rsq=c(.y, rep("", nrow(.x)-1))))) %>%

    dplyr::select(-Mod, -R.Squared) %>%
    unnest(data) %>%
    group_by(Metric) %>%
    nest()


# Explore the output
head(lfcTable.nested)
head(lfcTable.nested$data[[1]])


for (i in 1:nrow(lfcTable.nested)) {

    df <- lfcTable.nested$data[[i]]

    metric <- lfcTable.nested$Metric[i]

    # Create scatter plots presenting alignment discordance vs Variable
    p <- ggplot(df,
           aes(x=Variable.Value,
               y=Difference.Value,
               label=rsq)) + 
    geom_point(alpha=0.5) + 
    theme_bw() + 
    facet_grid(Difference ~ Variable, scales="free") + 
    theme(strip.text=element_text(size=11), 
          axis.text=element_text(size=10)) + 
    xlab("Variables") + 
    ylab("Discordance between HISAT2 and STAR") + 
    ggtitle(paste("Correlation between Variables and Alignment Discordance in", 
                  metric, "\n(with R-Squared)")) + 
    geom_text(size=5, mapping=aes(x=Inf, y=Inf), vjust=2, hjust=1.1, color="black") 

    print(p)

}




```


## Summarizing up/down-regulated DEGs using an upset plot

#### - The upset plot is designed to display intersecting DEG sets  

#### - References: [Lex et al., 2014](https://ieeexplore.ieee.org/document/6876017), [Conway et al., 2017](https://academic.oup.com/bioinformatics/article/33/18/2938/3884387), [GitHub](https://github.com/hms-dbmi/UpSetR)

```{r upset_plot, fig.height=10, fig.width=12}

# Generate a data frame storing upset input variables
upset.dataframe <- subset(lfc.dataframe, !is.na(padj)) %>%
    
    mutate(Up=ifelse(FDR == paste("<", alpha) & log2FoldChange > 0, GENEID, ""), 
           Down=ifelse(FDR == paste("<", alpha) & log2FoldChange < 0, GENEID, ""),
           Unchanged=ifelse(FDR == paste(">", alpha), GENEID, ""),
           STAR=ifelse(Alignment == "STAR", GENEID, ""),
           HISAT2=ifelse(Alignment == "HISAT2", GENEID, ""))

# Generate a list input 
upset.input <- list(Up=upset.dataframe$Up, 
                    Down=upset.dataframe$Down,
                    Unchanged=upset.dataframe$Unchanged, 
                    HISAT2=upset.dataframe$HISAT2,
                    STAR=upset.dataframe$STAR)

# Create an upset plot
upset(fromList(upset.input), 
      sets=names(upset.input),   # What group to display 
      sets.x.label="Number of Genes per Intersection",
      order.by="freq",
      point.size=3,
      keep.order=T,
      sets.bar.color=c("red", "red", "red", "blue", "blue"),
      text.scale = 1.5, number.angles=30)





      
```

## Session Info

```{r session_info}

sessionInfo()

```

```


- config_paired.R (R config)


```

my.anno.db <- "EnsDb"  # DB for AnnotationHub 
my.species <- "Homo sapiens"   # Species of the input dataset


featurecounts.path <- list(HISAT2="../hisat2_output/featurecounts.tsv",
                           STAR="../star_output/featurecounts.tsv")  # Paths to featurecounts count matrices 



sample.csv <- "../config/sample_paired.csv"   # Path to the sample table csv file

alpha <- 0.1   # Set threshold FDR



mLog <- c(-1, 1)  # Set minimum log2 fold change of interest 

basemean.comparison.ylog <- T
lfc.comparison.ylog <- F
padj.comparison.ylog <- F



geneid.species <- "ENSG"  # Ensembl code for gene id given by species (e.g. ENSG (human), ENSMUSG (mouse))


```



- Errors: Bad Request (HTTP 400)

    - Reference: [API Error Codes](https://docs.rstudio.com/connect/1.7.2/api/#API-Error-Codes)

```


(snakemake_mapping) mira@mira-MS-7C90:~/Documents/programming/Bioinformatics/snakemake_star_hisat$ snakemake -j 8 --use-conda
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	align_hisat2
	1	align_star
	1	all
	1	deseq2
	1	featurecounts
	1	get_fastq
	6
Select jobs to execute...

[Tue May 11 20:13:54 2021]
rule get_fastq:
    output: fastq/Untreated1_1.fastq.gz, fastq/Untreated1_2.fastq.gz, fastq/Untreated2_1.fastq.gz, fastq/Untreated2_2.fastq.gz, fastq/Untreated3_1.fastq.gz, fastq/Untreated3_2.fastq.gz, fastq/Treated1_1.fastq.gz, fastq/Treated1_2.fastq.gz, fastq/Treated2_1.fastq.gz, fastq/Treated2_2.fastq.gz, fastq/Treated3_1.fastq.gz, fastq/Treated3_2.fastq.gz
    jobid: 5

Job counts:
	count	jobs
	1	get_fastq
	1
Read 12928713 spots for SRR8245176
Written 12928713 spots for SRR8245176
Read 12525467 spots for SRR8245177
Written 12525467 spots for SRR8245177
Read 12145797 spots for SRR8245178
Written 12145797 spots for SRR8245178
Read 12182934 spots for SRR8245179
Written 12182934 spots for SRR8245179
Read 12241191 spots for SRR8245180
Written 12241191 spots for SRR8245180
Read 12974834 spots for SRR8245181
Written 12974834 spots for SRR8245181
Read 74998936 spots total
Written 74998936 spots total
[Tue May 11 21:52:18 2021]
Finished job 5.
1 of 6 steps (17%) done
Select jobs to execute...

[Tue May 11 21:52:18 2021]
rule align_hisat2:
    input: fastq/Untreated1_1.fastq.gz, fastq/Untreated1_2.fastq.gz, fastq/Untreated2_1.fastq.gz, fastq/Untreated2_2.fastq.gz, fastq/Untreated3_1.fastq.gz, fastq/Untreated3_2.fastq.gz, fastq/Treated1_1.fastq.gz, fastq/Treated1_2.fastq.gz, fastq/Treated2_1.fastq.gz, fastq/Treated2_2.fastq.gz, fastq/Treated3_1.fastq.gz, fastq/Treated3_2.fastq.gz, reference/hisat2_index/hisat2_index.1.ht2, reference/hisat2_index/hisat2_index.2.ht2, reference/hisat2_index/hisat2_index.3.ht2, reference/hisat2_index/hisat2_index.4.ht2, reference/hisat2_index/hisat2_index.5.ht2, reference/hisat2_index/hisat2_index.6.ht2, reference/hisat2_index/hisat2_index.7.ht2, reference/hisat2_index/hisat2_index.8.ht2
    output: hisat2_output/Untreated1.bam, hisat2_output/Untreated2.bam, hisat2_output/Untreated3.bam, hisat2_output/Treated1.bam, hisat2_output/Treated2.bam, hisat2_output/Treated3.bam, hisat2_output/Untreated1.sam, hisat2_output/Untreated2.sam, hisat2_output/Untreated3.sam, hisat2_output/Treated1.sam, hisat2_output/Treated2.sam, hisat2_output/Treated3.sam
    jobid: 7
    threads: 8

Job counts:
	count	jobs
	1	align_hisat2
	1
12928713 reads; of these:
  12928713 (100.00%) were paired; of these:
    1022402 (7.91%) aligned concordantly 0 times
    11161764 (86.33%) aligned concordantly exactly 1 time
    744547 (5.76%) aligned concordantly >1 times
    ----
    1022402 pairs aligned concordantly 0 times; of these:
      271482 (26.55%) aligned discordantly 1 time
    ----
    750920 pairs aligned 0 times concordantly or discordantly; of these:
      1501840 mates make up the pairs; of these:
        1039641 (69.22%) aligned 0 times
        408049 (27.17%) aligned exactly 1 time
        54150 (3.61%) aligned >1 times
95.98% overall alignment rate
12525467 reads; of these:
  12525467 (100.00%) were paired; of these:
    967756 (7.73%) aligned concordantly 0 times
    11005537 (87.87%) aligned concordantly exactly 1 time
    552174 (4.41%) aligned concordantly >1 times
    ----
    967756 pairs aligned concordantly 0 times; of these:
      263711 (27.25%) aligned discordantly 1 time
    ----
    704045 pairs aligned 0 times concordantly or discordantly; of these:
      1408090 mates make up the pairs; of these:
        946349 (67.21%) aligned 0 times
        412547 (29.30%) aligned exactly 1 time
        49194 (3.49%) aligned >1 times
96.22% overall alignment rate
12145797 reads; of these:
  12145797 (100.00%) were paired; of these:
    1177291 (9.69%) aligned concordantly 0 times
    10444399 (85.99%) aligned concordantly exactly 1 time
    524107 (4.32%) aligned concordantly >1 times
    ----
    1177291 pairs aligned concordantly 0 times; of these:
      313058 (26.59%) aligned discordantly 1 time
    ----
    864233 pairs aligned 0 times concordantly or discordantly; of these:
      1728466 mates make up the pairs; of these:
        1241341 (71.82%) aligned 0 times
        432831 (25.04%) aligned exactly 1 time
        54294 (3.14%) aligned >1 times
94.89% overall alignment rate
12182934 reads; of these:
  12182934 (100.00%) were paired; of these:
    948136 (7.78%) aligned concordantly 0 times
    10642842 (87.36%) aligned concordantly exactly 1 time
    591956 (4.86%) aligned concordantly >1 times
    ----
    948136 pairs aligned concordantly 0 times; of these:
      245882 (25.93%) aligned discordantly 1 time
    ----
    702254 pairs aligned 0 times concordantly or discordantly; of these:
      1404508 mates make up the pairs; of these:
        1007297 (71.72%) aligned 0 times
        349987 (24.92%) aligned exactly 1 time
        47224 (3.36%) aligned >1 times
95.87% overall alignment rate
12241191 reads; of these:
  12241191 (100.00%) were paired; of these:
    1038454 (8.48%) aligned concordantly 0 times
    10599308 (86.59%) aligned concordantly exactly 1 time
    603429 (4.93%) aligned concordantly >1 times
    ----
    1038454 pairs aligned concordantly 0 times; of these:
      261588 (25.19%) aligned discordantly 1 time
    ----
    776866 pairs aligned 0 times concordantly or discordantly; of these:
      1553732 mates make up the pairs; of these:
        1132045 (72.86%) aligned 0 times
        370531 (23.85%) aligned exactly 1 time
        51156 (3.29%) aligned >1 times
95.38% overall alignment rate
12974834 reads; of these:
  12974834 (100.00%) were paired; of these:
    966195 (7.45%) aligned concordantly 0 times
    11409721 (87.94%) aligned concordantly exactly 1 time
    598918 (4.62%) aligned concordantly >1 times
    ----
    966195 pairs aligned concordantly 0 times; of these:
      248349 (25.70%) aligned discordantly 1 time
    ----
    717846 pairs aligned 0 times concordantly or discordantly; of these:
      1435692 mates make up the pairs; of these:
        1005630 (70.04%) aligned 0 times
        378947 (26.39%) aligned exactly 1 time
        51115 (3.56%) aligned >1 times
96.12% overall alignment rate
Removing temporary output file hisat2_output/Untreated1.sam.
Removing temporary output file hisat2_output/Untreated2.sam.
Removing temporary output file hisat2_output/Untreated3.sam.
Removing temporary output file hisat2_output/Treated1.sam.
Removing temporary output file hisat2_output/Treated2.sam.
Removing temporary output file hisat2_output/Treated3.sam.
[Tue May 11 22:09:27 2021]
Finished job 7.
2 of 6 steps (33%) done
Select jobs to execute...

[Tue May 11 22:09:27 2021]
rule align_star:
    input: reference/gencode.v37.primary_assembly.annotation.gtf, fastq/Untreated1_1.fastq.gz, fastq/Untreated1_2.fastq.gz, fastq/Untreated2_1.fastq.gz, fastq/Untreated2_2.fastq.gz, fastq/Untreated3_1.fastq.gz, fastq/Untreated3_2.fastq.gz, fastq/Treated1_1.fastq.gz, fastq/Treated1_2.fastq.gz, fastq/Treated2_1.fastq.gz, fastq/Treated2_2.fastq.gz, fastq/Treated3_1.fastq.gz, fastq/Treated3_2.fastq.gz, reference/star_index/Genome, reference/star_index/SA, reference/star_index/SAindex
    output: star_output/Untreated1Aligned.sortedByCoord.out.bam, star_output/Untreated2Aligned.sortedByCoord.out.bam, star_output/Untreated3Aligned.sortedByCoord.out.bam, star_output/Treated1Aligned.sortedByCoord.out.bam, star_output/Treated2Aligned.sortedByCoord.out.bam, star_output/Treated3Aligned.sortedByCoord.out.bam
    jobid: 3
    threads: 8

Job counts:
	count	jobs
	1	align_star
	1
May 11 22:09:28 ..... started STAR run
May 11 22:09:28 ..... loading genome
May 11 22:09:53 ..... processing annotations GTF
May 11 22:10:04 ..... inserting junctions into the genome indices
May 11 22:10:56 ..... started 1st pass mapping
May 11 22:12:34 ..... finished 1st pass mapping
May 11 22:12:34 ..... inserting junctions into the genome indices
May 11 22:13:39 ..... started mapping
May 11 22:15:34 ..... finished mapping
May 11 22:15:36 ..... started sorting BAM
May 11 22:15:49 ..... finished successfully
May 11 22:15:50 ..... started STAR run
May 11 22:15:50 ..... loading genome
May 11 22:16:14 ..... processing annotations GTF
May 11 22:16:25 ..... inserting junctions into the genome indices
May 11 22:17:17 ..... started 1st pass mapping
May 11 22:18:49 ..... finished 1st pass mapping
May 11 22:18:49 ..... inserting junctions into the genome indices
May 11 22:19:55 ..... started mapping
May 11 22:21:46 ..... finished mapping
May 11 22:21:47 ..... started sorting BAM
May 11 22:22:00 ..... finished successfully
May 11 22:22:00 ..... started STAR run
May 11 22:22:00 ..... loading genome
May 11 22:22:26 ..... processing annotations GTF
May 11 22:22:37 ..... inserting junctions into the genome indices
May 11 22:23:29 ..... started 1st pass mapping
May 11 22:25:01 ..... finished 1st pass mapping
May 11 22:25:02 ..... inserting junctions into the genome indices
May 11 22:26:07 ..... started mapping
May 11 22:27:55 ..... finished mapping
May 11 22:27:57 ..... started sorting BAM
May 11 22:28:08 ..... finished successfully
May 11 22:28:09 ..... started STAR run
May 11 22:28:09 ..... loading genome
May 11 22:28:35 ..... processing annotations GTF
May 11 22:28:45 ..... inserting junctions into the genome indices
May 11 22:29:39 ..... started 1st pass mapping
May 11 22:31:08 ..... finished 1st pass mapping
May 11 22:31:08 ..... inserting junctions into the genome indices
May 11 22:32:12 ..... started mapping
May 11 22:34:10 ..... finished mapping
May 11 22:34:11 ..... started sorting BAM
May 11 22:34:23 ..... finished successfully
May 11 22:34:24 ..... started STAR run
May 11 22:34:24 ..... loading genome
May 11 22:34:44 ..... processing annotations GTF
May 11 22:34:54 ..... inserting junctions into the genome indices
May 11 22:35:48 ..... started 1st pass mapping
May 11 22:37:17 ..... finished 1st pass mapping
May 11 22:37:17 ..... inserting junctions into the genome indices
May 11 22:38:22 ..... started mapping
May 11 22:40:21 ..... finished mapping
May 11 22:40:22 ..... started sorting BAM
May 11 22:40:35 ..... finished successfully
May 11 22:40:35 ..... started STAR run
May 11 22:40:35 ..... loading genome
May 11 22:40:51 ..... processing annotations GTF
May 11 22:41:01 ..... inserting junctions into the genome indices
May 11 22:41:54 ..... started 1st pass mapping
May 11 22:43:26 ..... finished 1st pass mapping
May 11 22:43:27 ..... inserting junctions into the genome indices
May 11 22:44:33 ..... started mapping
May 11 22:46:43 ..... finished mapping
May 11 22:46:44 ..... started sorting BAM
May 11 22:46:57 ..... finished successfully
[Tue May 11 22:46:58 2021]
Finished job 3.
3 of 6 steps (50%) done
Select jobs to execute...

[Tue May 11 22:46:58 2021]
rule featurecounts:
    input: star_output/Untreated1Aligned.sortedByCoord.out.bam, star_output/Untreated2Aligned.sortedByCoord.out.bam, star_output/Untreated3Aligned.sortedByCoord.out.bam, star_output/Treated1Aligned.sortedByCoord.out.bam, star_output/Treated2Aligned.sortedByCoord.out.bam, star_output/Treated3Aligned.sortedByCoord.out.bam, hisat2_output/Untreated1.bam, hisat2_output/Untreated2.bam, hisat2_output/Untreated3.bam, hisat2_output/Treated1.bam, hisat2_output/Treated2.bam, hisat2_output/Treated3.bam
    output: star_output/featurecounts.tsv, hisat2_output/featurecounts.tsv
    jobid: 2
    threads: 8

Job counts:
	count	jobs
	1	featurecounts
	1
[Tue May 11 22:48:02 2021]
Finished job 2.
4 of 6 steps (67%) done
Select jobs to execute...

[Tue May 11 22:48:02 2021]
rule deseq2:
    input: star_output/featurecounts.tsv, hisat2_output/featurecounts.tsv, DE_analysis/DE.Rmd, config/config_single.R
    output: DE_analysis/DE.html, DE_analysis/lfc_STAR.csv, DE_analysis/lfc_HISAT2.csv, DE_analysis/baseMean_difference.csv, DE_analysis/log2FoldChange_difference.csv, DE_analysis/padj_difference.csv, DE_analysis/trf_input.fa
    jobid: 1

Activating conda environment: /home/mira/Documents/programming/Bioinformatics/snakemake_star_hisat/.snakemake/conda/f66a882151a23b1708e7d8b19c2fee6c


processing file: DE.Rmd
  |.                                                                     |   1%
  ordinary text without R code

  |..                                                                    |   3%
label: global_options (with options) 
List of 1
 $ include: logi FALSE

  |...                                                                   |   4%
  ordinary text without R code

  |....                                                                  |   6%
label: loading_packages
── Attaching packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.1 ──
✔ ggplot2 3.3.3     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.1
── Conflicts ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::between()   masks data.table::between()
✖ dplyr::filter()    masks stats::filter()
✖ dplyr::first()     masks data.table::first()
✖ dplyr::lag()       masks stats::lag()
✖ dplyr::last()      masks data.table::last()
✖ purrr::transpose() masks data.table::transpose()
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: 'BiocGenerics'

The following objects are masked from 'package:parallel':

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following objects are masked from 'package:dplyr':

    combine, intersect, setdiff, union

The following objects are masked from 'package:stats':

    IQR, mad, sd, var, xtabs

The following objects are masked from 'package:base':

    anyDuplicated, append, as.data.frame, basename, cbind, colnames,
    dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep,
    grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget,
    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,
    union, unique, unsplit, which.max, which.min

Loading required package: BiocFileCache
Loading required package: dbplyr

Attaching package: 'dbplyr'

The following objects are masked from 'package:dplyr':

    ident, sql

Loading required package: S4Vectors
Loading required package: stats4

Attaching package: 'S4Vectors'

The following objects are masked from 'package:dplyr':

    first, rename

The following object is masked from 'package:tidyr':

    expand

The following objects are masked from 'package:data.table':

    first, second

The following object is masked from 'package:base':

    expand.grid

Loading required package: IRanges

Attaching package: 'IRanges'

The following objects are masked from 'package:dplyr':

    collapse, desc, slice

The following object is masked from 'package:purrr':

    reduce

The following object is masked from 'package:data.table':

    shift

Loading required package: GenomicRanges
Loading required package: GenomeInfoDb
Loading required package: SummarizedExperiment
Loading required package: MatrixGenerics
Loading required package: matrixStats

Attaching package: 'matrixStats'

The following object is masked from 'package:dplyr':

    count


Attaching package: 'MatrixGenerics'

The following objects are masked from 'package:matrixStats':

    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,
    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,
    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,
    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,
    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,
    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,
    colWeightedMeans, colWeightedMedians, colWeightedSds,
    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,
    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,
    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,
    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,
    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,
    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,
    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,
    rowWeightedSds, rowWeightedVars

Loading required package: Biobase
Welcome to Bioconductor

    Vignettes contain introductory material; view with
    'browseVignettes()'. To cite Bioconductor, see
    'citation("Biobase")', and for packages 'citation("pkgname")'.


Attaching package: 'Biobase'

The following object is masked from 'package:MatrixGenerics':

    rowMedians

The following objects are masked from 'package:matrixStats':

    anyMissing, rowMedians

The following object is masked from 'package:AnnotationHub':

    cache

Loading required package: GenomicFeatures
Loading required package: AnnotationDbi

Attaching package: 'AnnotationDbi'

The following object is masked from 'package:dplyr':

    select

Loading required package: AnnotationFilter

Attaching package: 'ensembldb'

The following object is masked from 'package:dplyr':

    filter

The following object is masked from 'package:stats':

    filter


Attaching package: 'gridExtra'

The following object is masked from 'package:Biobase':

    combine

The following object is masked from 'package:BiocGenerics':

    combine

The following object is masked from 'package:dplyr':

    combine


Attaching package: 'httr'

The following object is masked from 'package:Biobase':

    content


Attaching package: 'jsonlite'

The following object is masked from 'package:purrr':

    flatten

  |.....                                                                 |   7%
  ordinary text without R code

  |......                                                                |   9%
label: unnamed-chunk-1
  |.......                                                               |  10%
  ordinary text without R code

  |........                                                              |  12%
label: annotationhub
snapshotDate(): 2020-10-27
loading from cache
  |.........                                                             |  13%
  ordinary text without R code

  |..........                                                            |  14%
label: read_countmatrix
  |...........                                                           |  16%
  ordinary text without R code

  |............                                                          |  17%
label: generating_metadata
  |.............                                                         |  19%
  ordinary text without R code

  |..............                                                        |  20%
label: count_dataframe_cleaning
  |...............                                                       |  22%
  ordinary text without R code

  |................                                                      |  23%
label: library_size
  |.................                                                     |  25%
  ordinary text without R code

  |..................                                                    |  26%
label: generating_deseq2_objects
  |...................                                                   |  28%
  ordinary text without R code

  |....................                                                  |  29%
label: size_factors
  |.....................                                                 |  30%
  ordinary text without R code

  |......................                                                |  32%
label: dispersion_waldtest
gene-wise dispersion estimates
mean-dispersion relationship
final dispersion estimates
gene-wise dispersion estimates
mean-dispersion relationship
final dispersion estimates
  |.......................                                               |  33%
  ordinary text without R code

  |........................                                              |  35%
label: QC_PCA
  |.........................                                             |  36%
  ordinary text without R code

  |..........................                                            |  38%
label: QC_correlation_heatmap
  |...........................                                           |  39%
  ordinary text without R code

  |............................                                          |  41%
label: DE_analysis
using pre-existing size factors
estimating dispersions
found already estimated dispersions, replacing these
gene-wise dispersion estimates
mean-dispersion relationship
final dispersion estimates
fitting model and testing
using pre-existing size factors
estimating dispersions
found already estimated dispersions, replacing these
gene-wise dispersion estimates
mean-dispersion relationship
final dispersion estimates
fitting model and testing
  |.............................                                         |  42%
  ordinary text without R code

  |..............................                                        |  43%
label: dispersion_plot
  |...............................                                       |  45%
  ordinary text without R code

  |................................                                      |  46%
label: setting_resultcondition
  |.................................                                     |  48%
  ordinary text without R code

  |..................................                                    |  49%
label: DEresult_extraction
  |....................................                                  |  51%
  ordinary text without R code

  |.....................................                                 |  52%
label: FDR_distribution
Scale for 'x' is already present. Adding another scale for 'x', which will
replace the existing scale.
  |......................................                                |  54%
  ordinary text without R code

  |.......................................                               |  55%
label: L2FC_distribution
  |........................................                              |  57%
  ordinary text without R code

  |.........................................                             |  58%
label: MAplot
  |..........................................                            |  59%
  ordinary text without R code

  |...........................................                           |  61%
label: expression_heatmap
  |............................................                          |  62%
  ordinary text without R code

  |.............................................                         |  64%
label: NA_genes
  |..............................................                        |  65%
  ordinary text without R code

  |...............................................                       |  67%
label: diff_prep
  |................................................                      |  68%
  ordinary text without R code

  |.................................................                     |  70%
label: comparison (with options) 
List of 1
 $ fig_width: num 12

  |..................................................                    |  71%
  ordinary text without R code

  |...................................................                   |  72%
label: distribution (with options) 
List of 2
 $ fig.height: num 12
 $ fig.width : num 12

  |....................................................                  |  74%
  ordinary text without R code

  |.....................................................                 |  75%
label: percent_difference (with options) 
List of 1
 $ fig.width: num 12

  |......................................................                |  77%
  ordinary text without R code

  |.......................................................               |  78%
label: ranking_comparison_prep
  |........................................................              |  80%
  ordinary text without R code

  |.........................................................             |  81%
label: ranking_comparison (with options) 
List of 1
 $ fig.width: num 12

  |..........................................................            |  83%
  ordinary text without R code

  |...........................................................           |  84%
label: saving_diff_csv
  |............................................................          |  86%
  ordinary text without R code

  |.............................................................         |  87%
label: count_repetitive_elements
Quitting from lines 1336-1484 (DE.Rmd) 
Error in eval(expr, envir, enclos) : Bad Request (HTTP 400).
Calls: <Anonymous> ... withCallingHandlers -> withVisible -> eval -> eval -> stop_for_status
In addition: There were 11 warnings (use warnings() to see them)

Execution halted
[Tue May 11 23:18:57 2021]
Error in rule deseq2:
    jobid: 1
    output: DE_analysis/DE.html, DE_analysis/lfc_STAR.csv, DE_analysis/lfc_HISAT2.csv, DE_analysis/baseMean_difference.csv, DE_analysis/log2FoldChange_difference.csv, DE_analysis/padj_difference.csv, DE_analysis/trf_input.fa
    conda-env: /home/mira/Documents/programming/Bioinformatics/snakemake_star_hisat/.snakemake/conda/f66a882151a23b1708e7d8b19c2fee6c
    shell:
        Rscript -e "rmarkdown::render('DE_analysis/DE.Rmd')"
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job deseq2 since they might be corrupted:
DE_analysis/lfc_STAR.csv, DE_analysis/lfc_HISAT2.csv, DE_analysis/baseMean_difference.csv, DE_analysis/log2FoldChange_difference.csv, DE_analysis/padj_difference.csv, DE_analysis/trf_input.fa
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/mira/Documents/programming/Bioinformatics/snakemake_star_hisat/.snakemake/log/2021-05-11T201354.177614.snakemake.log

```
